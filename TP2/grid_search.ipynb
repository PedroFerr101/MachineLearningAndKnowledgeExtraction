{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, KBinsDiscretizer\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectPercentile, GenericUnivariateSelect, RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsenteeismAtWork = pd.read_csv('data/train_data.csv', index_col=0)\n",
    "AbsenteeismAtWork['Work load Average/day '] = [x.replace(',', '') for x in AbsenteeismAtWork['Work load Average/day ']]\n",
    "AbsenteeismAtWork['Work load Average/day '] = AbsenteeismAtWork['Work load Average/day '].astype(int)\n",
    "\n",
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustScaling2(X_train, X_test):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    scaled_test = scaler.transform( X_test )\n",
    "    return scaled_data, scaled_test;\n",
    "\n",
    "def discretize2(X_train, X_test):\n",
    "    featuresToDiscretize = ['Transportation expense', 'Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Hit target', 'Weight', 'Height', 'Body mass index']\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    X_train[featuresToDiscretize] = discretizer.fit_transform(X_train[featuresToDiscretize])\n",
    "    X_test[featuresToDiscretize] = discretizer.transform(X_test[featuresToDiscretize])\n",
    "    return X_train, X_test;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteeenSampler(X_train, y_train):\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_balanced, y_train = smote_enn.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n",
    "\n",
    "def smotetomekSampler(X_train, y_train):\n",
    "    smote_tomek = SMOTETomek(random_state=0)\n",
    "    X_balanced, y_train = smote_tomek.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n",
    "\n",
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectKBest_f_classif(X_train, y_train, X_test):\n",
    "    kbest_selector_f_classif = SelectKBest(f_classif, k=8)\n",
    "    selector = kbest_selector_f_classif.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = kbest_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectKBest_chi2(X_train, y_train, X_test):\n",
    "    kbest_selector_chi2 = SelectKBest(chi2, k=8)\n",
    "    selector = kbest_selector_chi2.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_chi2.transform(X_train)\n",
    "    X_test_selected = kbest_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectPercentile_f_classif(X_train, y_train, X_test):\n",
    "    percentile_selector_f_classif = SelectPercentile(f_classif, percentile=25)\n",
    "    selector = percentile_selector_f_classif.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = percentile_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectPercentile_chi2(X_train, y_train, X_test):\n",
    "    percentile_selector_chi2 = SelectPercentile(chi2, percentile=25)\n",
    "    selector = percentile_selector_chi2.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_chi2.transform(X_train)\n",
    "    X_test_selected = percentile_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def selectVarianceThreshold(X_train, y_train, X_test):\n",
    "    varianceThreshold_selector = VarianceThreshold()\n",
    "    selector = varianceThreshold_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = varianceThreshold_selector.transform(X_train)\n",
    "    X_test_selected = varianceThreshold_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectGenericUnivariateSelect(X_train, y_train, X_test):\n",
    "    gus_selector = GenericUnivariateSelect(f_classif, 'k_best', param=19)\n",
    "    selector = gus_selector.fit(X_train, y_train)\n",
    "    X_train_selected = gus_selector.transform(X_train)\n",
    "    X_test_selected = gus_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def rfeLogReg(X_train, y_train, X_test):\n",
    "    rfe_log_selector = RFE(LogisticRegression(), 12)\n",
    "    selector = rfe_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_log_selector.transform(X_train)\n",
    "    X_test_selected = rfe_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def rfeSVC(X_train, y_train, X_test):\n",
    "    rfe_svc_selector = RFE(SVC(kernel='linear'), 12)\n",
    "    selector = rfe_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfe_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def sfmTree(X_train, y_train, X_test):\n",
    "    tree_selector = ExtraTreesClassifier(n_estimators=50)\n",
    "    selector = tree_selector.fit(X_train, y_train)\n",
    "    sfm_Tree_selector = SelectFromModel(tree_selector, prefit=True)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = sfm_Tree_selector.transform(X_train)\n",
    "    X_test_selected = sfm_Tree_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções para grid search e aplicação das técnicas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test):        \n",
    "    clf = GridSearchCV(model, param_grid, refit=True, verbose=0)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(clf.best_params_)\n",
    "    predicted = clf.predict(X_test)\n",
    "    evaluateModel(modelName, y_test, predicted)\n",
    "    return ;\n",
    "    \n",
    "    \n",
    "def apllyGridSearchWithTransformation(model, transformer, param_grid, modelName):\n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "    X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    \n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "\n",
    "def apllyGridSearchWithFSelect(model, transformer, selector, param_grid, modelName):\n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "    X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    X_train, X_test = selector(X_train, y_train, X_test)\n",
    "    \n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "def apllyGridSearchWithLoadBalancing(model, transformer, selector, balancer, param_grid, modelName):\n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "    X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    X_train, y_train = balancer(X_train, y_train)\n",
    "    X_train, X_test = selector(X_train, y_train, X_test)\n",
    "\n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "\n",
    "def evaluateModel(name, y_test, predicted):\n",
    "    print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), name)\n",
    "    return;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC com robust scaling + select variance threshold + smoteenSampler:\n",
      "{'C': 100, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf'}\n",
      "Accuracy: 0.704 || AUROC 0.510 || (Accuracy, Precision) 0:( 0.205, 0.200)  1:( 0.816, 0.821) -> SVC\n",
      "SVC com discretizacao e select selectPercentile_chi2 + over sampler:\n",
      "{'C': 10, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf'}\n",
      "Accuracy: 0.692 || AUROC 0.494 || (Accuracy, Precision) 0:( 0.182, 0.174)  1:( 0.806, 0.814) -> SVC\n",
      "SVC com discretizacao e select selectVarianceThreshold + over sampler:\n",
      "{'C': 1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf'}\n",
      "Accuracy: 0.812 || AUROC 0.497 || (Accuracy, Precision) 0:( 0.000, 0.000)  1:( 0.995, 0.816) -> SVC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid_svc = {\n",
    "    'class_weight': ['balanced', None], \n",
    "    'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001], \n",
    "    'kernel': ['rbf', 'linear']\n",
    "} \n",
    "print(\"SVC com robust scaling + select variance threshold + smoteenSampler:\")\n",
    "apllyGridSearchWithLoadBalancing(SVC(), robustScaling2, selectPercentile_f_classif, overSampler, param_grid_svc, \"SVC\")\n",
    "print(\"SVC com discretizacao e select selectPercentile_chi2 + over sampler:\")\n",
    "apllyGridSearchWithLoadBalancing(SVC(), discretize2, selectPercentile_chi2, overSampler, param_grid_svc, \"SVC\")\n",
    "print(\"SVC com discretizacao e select selectVarianceThreshold + over sampler:\")\n",
    "apllyGridSearchWithLoadBalancing(SVC(), discretize2, selectVarianceThreshold, overSampler, param_grid_svc, \"SVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "Accuracy: 0.667 || AUROC 0.540 || (Accuracy, Precision) 0:( 0.341, 0.227)  1:( 0.740, 0.833) -> knn\n",
      "{'metric': 'euclidean', 'n_neighbors': 50, 'weights': 'distance'}\n",
      "Accuracy: 0.637 || AUROC 0.531 || (Accuracy, Precision) 0:( 0.364, 0.213)  1:( 0.699, 0.830) -> knn\n",
      "{'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "Accuracy: 0.688 || AUROC 0.535 || (Accuracy, Precision) 0:( 0.295, 0.228)  1:( 0.776, 0.831) -> knn\n"
     ]
    }
   ],
   "source": [
    "grid_params_knn = {\n",
    "    'n_neighbors' : [3,5,7,11,13, 15, 17, 25, 30, 50],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'metric' : ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretize2, selectPercentile_chi2, overSampler, grid_params_knn, \"knn\")\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretize2, selectPercentile_chi2, smotetomekSampler, grid_params_knn, \"knn\")\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretize2, selectKBest_f_classif, overSampler, grid_params_knn, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'max_depth': 20, 'n_estimators': 100}\n",
      "Accuracy: 0.704 || AUROC 0.528 || (Accuracy, Precision) 0:( 0.250, 0.224)  1:( 0.806, 0.827) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "grid_params_randomforest = {\n",
    "    'n_estimators' : [10,20,30,50,100,200,1000],\n",
    "    'max_depth' : [1, 10, 20, None],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(RandomForestClassifier(), discretize2, selectPercentile_chi2, overSampler, grid_params_randomforest, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiLayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 1e-05, 'hidden_layer_sizes': 200, 'max_iter': 1000, 'shuffle': True, 'solver': 'adam'}\n",
      "Accuracy: 0.713 || AUROC 0.533 || (Accuracy, Precision) 0:( 0.250, 0.234)  1:( 0.816, 0.829) -> mlp\n"
     ]
    }
   ],
   "source": [
    "grid_params_mlp = {\n",
    "    'solver': ['adam'],\n",
    "    'activation': ['identity', 'logistic','tanh'],\n",
    "    'max_iter': [1000],\n",
    "    'shuffle': [True],\n",
    "    'alpha': 10.0 ** -np.arange(3, 7),\n",
    "    'hidden_layer_sizes': [100, 150, 200],\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(MLPClassifier(), discretize2, selectPercentile_chi2, overSampler, grid_params_mlp, \"mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.729 || AUROC 0.570 || (Accuracy, Precision) 0:( 0.318, 0.286)  1:( 0.821, 0.843) -> categoricalnb\n"
     ]
    }
   ],
   "source": [
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "X_train, X_test = discretize2(X_train, X_test)\n",
    "X_train, X_test = selectPercentile_chi2(X_train, y_train, X_test)\n",
    "X_train, y_train = overSampler(X_train, y_train)\n",
    "\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), \"categoricalnb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.733 || AUROC 0.564 || (Accuracy, Precision) 0:( 0.295, 0.283)  1:( 0.832, 0.840) -> categoricalnb\n"
     ]
    }
   ],
   "source": [
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), \"categoricalnb\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.721 || AUROC 0.529 || (Accuracy, Precision) 0:( 0.227, 0.233)  1:( 0.832, 0.827) -> voting classifier\n"
     ]
    }
   ],
   "source": [
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "X_train, X_test = discretize2(X_train, X_test)\n",
    "X_train, X_test = selectPercentile_chi2(X_train, y_train, X_test)\n",
    "X_train, y_train = overSampler(X_train, y_train)\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = SVC(C= 100, class_weight = 'balanced', gamma= 0.1, kernel= 'rbf')\n",
    "clf3 = KNeighborsClassifier(metric= 'manhattan', n_neighbors = 17, weights = 'distance')\n",
    "clf4 = CategoricalNB()\n",
    "clf5 = RandomForestClassifier(bootstrap= False, max_depth= 10, n_estimators= 2000)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), ('svc', clf2), ('knn', clf3), ('cnb', clf4), ('rfc', clf5)], voting='hard')\n",
    "\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "\n",
    "predicted = eclf1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), \"voting classifier\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
