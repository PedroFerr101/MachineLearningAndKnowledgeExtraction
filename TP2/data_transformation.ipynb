{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, KBinsDiscretizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsenteeismAtWork = pd.read_csv('data/train_data.csv', index_col=0)\n",
    "AbsenteeismAtWork['Work load Average/day '] = [x.replace(',', '') for x in AbsenteeismAtWork['Work load Average/day ']]\n",
    "AbsenteeismAtWork['Work load Average/day '] = AbsenteeismAtWork['Work load Average/day '].astype(int)\n",
    "\n",
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardScaling(X_train): \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    return scaled_data;\n",
    "\n",
    "def standardScaling2(X_train, X_test): \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    scaled_test = scaler.transform( X_test )\n",
    "    return scaled_data, scaled_test;\n",
    "\n",
    "\n",
    "def robustScaling(X_train):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    return scaled_data;\n",
    "\n",
    "def robustScaling2(X_train, X_test):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    scaled_test = scaler.transform( X_test )\n",
    "    return scaled_data, scaled_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(X_train):\n",
    "    featuresToDiscretize = ['Transportation expense', 'Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Hit target', 'Weight', 'Height', 'Body mass index']\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    X_train[featuresToDiscretize] = discretizer.fit_transform(X_train[featuresToDiscretize])\n",
    "    return X_train;\n",
    "\n",
    "def discretize2(X_train, X_test):\n",
    "    featuresToDiscretize = ['Transportation expense', 'Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Hit target', 'Weight', 'Height', 'Body mass index']\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    X_train[featuresToDiscretize] = discretizer.fit_transform(X_train[featuresToDiscretize])\n",
    "    X_test[featuresToDiscretize] = discretizer.transform(X_test[featuresToDiscretize])\n",
    "    return X_train, X_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train):\n",
    "    X_train = transformer = Normalizer().fit_transform(X_train)\n",
    "    return X_train;\n",
    "\n",
    "def normalize2(X_train, X_test):\n",
    "    normalizer = Normalizer()\n",
    "    X_train = normalizer.fit_transform(X_train)\n",
    "    X_test = normalizer.transform(X_test)\n",
    "    return X_train, X_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Técnica combinada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretizeAndScale(X_train):\n",
    "    X_train = discretize(X_train)\n",
    "    X_train = robustScaling(X_train)\n",
    "    return X_train;\n",
    "\n",
    "def discretizeAndScale2(X_train, X_test):\n",
    "    X_train = discretize2(X_train, X_test)\n",
    "    X_train = robustScaling2(X_train, X_test)\n",
    "    return X_train, X_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação das técnicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTechnique(transformer):\n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "\n",
    "    X_train = transformer(X_train)\n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(),\n",
    "        SGDClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        SVC(),\n",
    "        LinearSVC(max_iter=10000),\n",
    "        GaussianNB(),\n",
    "        GaussianProcessClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        MLPClassifier(max_iter=10000),\n",
    "        AdaBoostClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "    ]\n",
    "\n",
    "    names = [\n",
    "             \"Logistic regression\", \"SGDClassifier\",\n",
    "             \"KNearest Neighbors (5)\", \n",
    "             \"SVM-rbf\", \"SMV-linear\", \n",
    "             \"Gaussian naive bayes\",\n",
    "             \"Gaussian Process\", \n",
    "             \"Decision Tree\", \n",
    "             \"Multi-layer Perceptron\", \n",
    "             \"AdaBoost\", \"Random Forest\"]\n",
    "\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        scores = cross_validate(clf, X_train, y_train, cv=10, scoring={'accuracy', 'roc_auc'})\n",
    "        print(\"Accuracy: %0.3f (+/- %0.3f) || AUROC %0.3f ->\" % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2, scores['test_roc_auc'].mean()), name)\n",
    "        \n",
    "    return;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.822 (+/- 0.126) || AUROC 0.708 -> Logistic regression\n",
      "Accuracy: 0.770 (+/- 0.226) || AUROC 0.697 -> SGDClassifier\n",
      "Accuracy: 0.812 (+/- 0.113) || AUROC 0.672 -> KNearest Neighbors (5)\n",
      "Accuracy: 0.850 (+/- 0.082) || AUROC 0.650 -> SVM-rbf\n",
      "Accuracy: 0.840 (+/- 0.093) || AUROC 0.707 -> SMV-linear\n",
      "Accuracy: 0.854 (+/- 0.084) || AUROC 0.653 -> Gaussian naive bayes\n",
      "Accuracy: 0.774 (+/- 0.120) || AUROC 0.589 -> Gaussian Process\n",
      "Accuracy: 0.778 (+/- 0.204) || AUROC 0.698 -> Decision Tree\n",
      "Accuracy: 0.784 (+/- 0.129) || AUROC 0.655 -> Multi-layer Perceptron\n",
      "Accuracy: 0.780 (+/- 0.244) || AUROC 0.737 -> AdaBoost\n",
      "Accuracy: 0.816 (+/- 0.085) || AUROC 0.687 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(standardScaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.834 (+/- 0.082) || AUROC 0.670 -> Logistic regression\n",
      "Accuracy: 0.744 (+/- 0.265) || AUROC 0.667 -> SGDClassifier\n",
      "Accuracy: 0.774 (+/- 0.088) || AUROC 0.594 -> KNearest Neighbors (5)\n",
      "Accuracy: 0.834 (+/- 0.093) || AUROC 0.615 -> SVM-rbf\n",
      "Accuracy: 0.844 (+/- 0.093) || AUROC 0.704 -> SMV-linear\n",
      "Accuracy: 0.854 (+/- 0.084) || AUROC 0.653 -> Gaussian naive bayes\n",
      "Accuracy: 0.772 (+/- 0.082) || AUROC 0.624 -> Gaussian Process\n",
      "Accuracy: 0.746 (+/- 0.207) || AUROC 0.677 -> Decision Tree\n",
      "Accuracy: 0.778 (+/- 0.125) || AUROC 0.674 -> Multi-layer Perceptron\n",
      "Accuracy: 0.780 (+/- 0.244) || AUROC 0.737 -> AdaBoost\n",
      "Accuracy: 0.814 (+/- 0.084) || AUROC 0.718 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(robustScaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838 (+/- 0.063) || AUROC 0.662 -> Logistic regression\n",
      "Accuracy: 0.802 (+/- 0.142) || AUROC 0.576 -> SGDClassifier\n",
      "Accuracy: 0.782 (+/- 0.081) || AUROC 0.653 -> KNearest Neighbors (5)\n",
      "Accuracy: 0.826 (+/- 0.065) || AUROC 0.670 -> SVM-rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846 (+/- 0.069) || AUROC 0.714 -> SMV-linear\n",
      "Accuracy: 0.854 (+/- 0.084) || AUROC 0.650 -> Gaussian naive bayes\n",
      "Accuracy: 0.716 (+/- 0.114) || AUROC 0.546 -> Gaussian Process\n",
      "Accuracy: 0.738 (+/- 0.201) || AUROC 0.672 -> Decision Tree\n",
      "Accuracy: 0.790 (+/- 0.090) || AUROC 0.678 -> Multi-layer Perceptron\n",
      "Accuracy: 0.752 (+/- 0.216) || AUROC 0.722 -> AdaBoost\n",
      "Accuracy: 0.816 (+/- 0.071) || AUROC 0.677 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(discretize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790 (+/- 0.020) || AUROC 0.569 -> Logistic regression\n",
      "Accuracy: 0.734 (+/- 0.343) || AUROC 0.566 -> SGDClassifier\n",
      "Accuracy: 0.756 (+/- 0.111) || AUROC 0.588 -> KNearest Neighbors (5)\n",
      "Accuracy: 0.790 (+/- 0.020) || AUROC 0.582 -> SVM-rbf\n",
      "Accuracy: 0.790 (+/- 0.020) || AUROC 0.569 -> SMV-linear\n",
      "Accuracy: 0.848 (+/- 0.072) || AUROC 0.617 -> Gaussian naive bayes\n",
      "Accuracy: 0.790 (+/- 0.020) || AUROC 0.568 -> Gaussian Process\n",
      "Accuracy: 0.754 (+/- 0.119) || AUROC 0.666 -> Decision Tree\n",
      "Accuracy: 0.790 (+/- 0.020) || AUROC 0.591 -> Multi-layer Perceptron\n",
      "Accuracy: 0.796 (+/- 0.126) || AUROC 0.683 -> AdaBoost\n",
      "Accuracy: 0.790 (+/- 0.128) || AUROC 0.687 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838 (+/- 0.068) || AUROC 0.675 -> Logistic regression\n",
      "Accuracy: 0.750 (+/- 0.265) || AUROC 0.658 -> SGDClassifier\n",
      "Accuracy: 0.762 (+/- 0.132) || AUROC 0.609 -> KNearest Neighbors (5)\n",
      "Accuracy: 0.824 (+/- 0.078) || AUROC 0.620 -> SVM-rbf\n",
      "Accuracy: 0.846 (+/- 0.069) || AUROC 0.714 -> SMV-linear\n",
      "Accuracy: 0.854 (+/- 0.084) || AUROC 0.650 -> Gaussian naive bayes\n",
      "Accuracy: 0.790 (+/- 0.138) || AUROC 0.620 -> Gaussian Process\n",
      "Accuracy: 0.732 (+/- 0.201) || AUROC 0.665 -> Decision Tree\n",
      "Accuracy: 0.776 (+/- 0.161) || AUROC 0.665 -> Multi-layer Perceptron\n",
      "Accuracy: 0.752 (+/- 0.216) || AUROC 0.722 -> AdaBoost\n",
      "Accuracy: 0.818 (+/- 0.068) || AUROC 0.695 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(discretizeAndScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTechniqueAgaintTestData(transformer):\n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "    X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "    \n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "\n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(),\n",
    "        SGDClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        SVC(),\n",
    "        LinearSVC(max_iter=10000),\n",
    "        GaussianNB(),\n",
    "        GaussianProcessClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        MLPClassifier(max_iter=10000),\n",
    "        AdaBoostClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "    ]\n",
    "\n",
    "    names = [\n",
    "             \"Logistic regression\", \"SGDClassifier\",\n",
    "             \"KNearest Neighbors (5)\", \n",
    "             \"SVM-rbf\", \"SMV-linear\", \n",
    "             \"Gaussian naive bayes\",\n",
    "             \"Gaussian Process\", \n",
    "             \"Decision Tree\", \n",
    "             \"Multi-layer Perceptron\", \n",
    "             \"AdaBoost\", \"Random Forest\"]\n",
    "\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "        evaluateModel(name, y_test, predicted)    \n",
    "    return;  \n",
    "\n",
    "\n",
    "def evaluateModel(name, y_test, predicted):\n",
    "    print(\"\".join([\"Precision 0: \",'%.3f' % precision_score(y_test,predicted,pos_label=0),\n",
    "                   \"; Precision 1: \",'%.3f' % precision_score(y_test,predicted,pos_label=1),\n",
    "                   \"; Recall 0: \",'%.3f' % recall_score(y_test,predicted,pos_label=0),\n",
    "                   \"; Recall 1: \",'%.3f' % recall_score(y_test,predicted,pos_label=1),\n",
    "                   \"; Accuracy: \",'%.3f' % accuracy_score(y_test,predicted), \n",
    "                   \"; AUROC: \",'%.3f' % roc_auc_score(y_test, predicted), \" -> \" ,name]))\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0: 0.353; Precision 1: 0.830; Recall 0: 0.136; Recall 1: 0.944; Accuracy: 0.796; AUROC: 0.540 -> Logistic regression\n",
      "Precision 0: 0.217; Precision 1: 0.828; Recall 0: 0.295; Recall 1: 0.760; Accuracy: 0.675; AUROC: 0.528 -> SGDClassifier\n",
      "Precision 0: 0.300; Precision 1: 0.822; Recall 0: 0.068; Recall 1: 0.964; Accuracy: 0.800; AUROC: 0.516 -> KNearest Neighbors (5)\n",
      "Precision 0: 0.375; Precision 1: 0.823; Recall 0: 0.068; Recall 1: 0.974; Accuracy: 0.808; AUROC: 0.521 -> SVM-rbf\n",
      "Precision 0: 0.375; Precision 1: 0.830; Recall 0: 0.136; Recall 1: 0.949; Accuracy: 0.800; AUROC: 0.543 -> SMV-linear\n",
      "Precision 0: 0.375; Precision 1: 0.823; Recall 0: 0.068; Recall 1: 0.974; Accuracy: 0.808; AUROC: 0.521 -> Gaussian naive bayes\n",
      "Precision 0: 0.286; Precision 1: 0.826; Recall 0: 0.136; Recall 1: 0.923; Accuracy: 0.779; AUROC: 0.530 -> Gaussian Process\n",
      "Precision 0: 0.298; Precision 1: 0.845; Recall 0: 0.318; Recall 1: 0.832; Accuracy: 0.738; AUROC: 0.575 -> Decision Tree\n",
      "Precision 0: 0.133; Precision 1: 0.810; Recall 0: 0.091; Recall 1: 0.867; Accuracy: 0.725; AUROC: 0.479 -> Multi-layer Perceptron\n",
      "Precision 0: 0.269; Precision 1: 0.827; Recall 0: 0.159; Recall 1: 0.903; Accuracy: 0.767; AUROC: 0.531 -> AdaBoost\n",
      "Precision 0: 0.267; Precision 1: 0.822; Recall 0: 0.091; Recall 1: 0.944; Accuracy: 0.787; AUROC: 0.517 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechniqueAgaintTestData(standardScaling2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0: 0.400; Precision 1: 0.831; Recall 0: 0.136; Recall 1: 0.954; Accuracy: 0.804; AUROC: 0.545 -> Logistic regression\n",
      "Precision 0: 0.211; Precision 1: 0.819; Recall 0: 0.091; Recall 1: 0.923; Accuracy: 0.771; AUROC: 0.507 -> SGDClassifier\n",
      "Precision 0: 0.200; Precision 1: 0.817; Recall 0: 0.023; Recall 1: 0.980; Accuracy: 0.804; AUROC: 0.501 -> KNearest Neighbors (5)\n",
      "Precision 0: 0.429; Precision 1: 0.824; Recall 0: 0.068; Recall 1: 0.980; Accuracy: 0.812; AUROC: 0.524 -> SVM-rbf\n",
      "Precision 0: 0.400; Precision 1: 0.831; Recall 0: 0.136; Recall 1: 0.954; Accuracy: 0.804; AUROC: 0.545 -> SMV-linear\n",
      "Precision 0: 0.375; Precision 1: 0.823; Recall 0: 0.068; Recall 1: 0.974; Accuracy: 0.808; AUROC: 0.521 -> Gaussian naive bayes\n",
      "Precision 0: 0.273; Precision 1: 0.821; Recall 0: 0.068; Recall 1: 0.959; Accuracy: 0.796; AUROC: 0.514 -> Gaussian Process\n",
      "Precision 0: 0.279; Precision 1: 0.838; Recall 0: 0.273; Recall 1: 0.842; Accuracy: 0.738; AUROC: 0.557 -> Decision Tree\n",
      "Precision 0: 0.154; Precision 1: 0.813; Recall 0: 0.091; Recall 1: 0.888; Accuracy: 0.742; AUROC: 0.489 -> Multi-layer Perceptron\n",
      "Precision 0: 0.240; Precision 1: 0.823; Recall 0: 0.136; Recall 1: 0.903; Accuracy: 0.762; AUROC: 0.520 -> AdaBoost\n",
      "Precision 0: 0.286; Precision 1: 0.826; Recall 0: 0.136; Recall 1: 0.923; Accuracy: 0.779; AUROC: 0.530 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechniqueAgaintTestData(robustScaling2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0: 0.353; Precision 1: 0.830; Recall 0: 0.136; Recall 1: 0.944; Accuracy: 0.796; AUROC: 0.540 -> Logistic regression\n",
      "Precision 0: 0.600; Precision 1: 0.826; Recall 0: 0.068; Recall 1: 0.990; Accuracy: 0.821; AUROC: 0.529 -> SGDClassifier\n",
      "Precision 0: 0.167; Precision 1: 0.815; Recall 0: 0.068; Recall 1: 0.923; Accuracy: 0.767; AUROC: 0.496 -> KNearest Neighbors (5)\n",
      "Precision 0: 0.312; Precision 1: 0.826; Recall 0: 0.114; Recall 1: 0.944; Accuracy: 0.792; AUROC: 0.529 -> SVM-rbf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0: 0.412; Precision 1: 0.834; Recall 0: 0.159; Recall 1: 0.949; Accuracy: 0.804; AUROC: 0.554 -> SMV-linear\n",
      "Precision 0: 0.333; Precision 1: 0.823; Recall 0: 0.068; Recall 1: 0.969; Accuracy: 0.804; AUROC: 0.519 -> Gaussian naive bayes\n",
      "Precision 0: 0.088; Precision 1: 0.801; Recall 0: 0.068; Recall 1: 0.842; Accuracy: 0.700; AUROC: 0.455 -> Gaussian Process\n",
      "Precision 0: 0.244; Precision 1: 0.831; Recall 0: 0.250; Recall 1: 0.827; Accuracy: 0.721; AUROC: 0.538 -> Decision Tree\n",
      "Precision 0: 0.229; Precision 1: 0.824; Recall 0: 0.182; Recall 1: 0.862; Accuracy: 0.738; AUROC: 0.522 -> Multi-layer Perceptron\n",
      "Precision 0: 0.231; Precision 1: 0.819; Recall 0: 0.068; Recall 1: 0.949; Accuracy: 0.787; AUROC: 0.509 -> AdaBoost\n",
      "Precision 0: 0.235; Precision 1: 0.821; Recall 0: 0.091; Recall 1: 0.934; Accuracy: 0.779; AUROC: 0.512 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechniqueAgaintTestData(discretize2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0: 0.000; Precision 1: 0.817; Recall 0: 0.000; Recall 1: 1.000; Accuracy: 0.817; AUROC: 0.500 -> Logistic regression\n",
      "Precision 0: 0.000; Precision 1: 0.817; Recall 0: 0.000; Recall 1: 1.000; Accuracy: 0.817; AUROC: 0.500 -> SGDClassifier\n",
      "Precision 0: 0.273; Precision 1: 0.826; Recall 0: 0.136; Recall 1: 0.918; Accuracy: 0.775; AUROC: 0.527 -> KNearest Neighbors (5)\n",
      "Precision 0: 0.000; Precision 1: 0.817; Recall 0: 0.000; Recall 1: 1.000; Accuracy: 0.817; AUROC: 0.500 -> SVM-rbf\n",
      "Precision 0: 0.000; Precision 1: 0.817; Recall 0: 0.000; Recall 1: 1.000; Accuracy: 0.817; AUROC: 0.500 -> SMV-linear\n",
      "Precision 0: 0.375; Precision 1: 0.823; Recall 0: 0.068; Recall 1: 0.974; Accuracy: 0.808; AUROC: 0.521 -> Gaussian naive bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0: 0.000; Precision 1: 0.817; Recall 0: 0.000; Recall 1: 1.000; Accuracy: 0.817; AUROC: 0.500 -> Gaussian Process\n",
      "Precision 0: 0.159; Precision 1: 0.808; Recall 0: 0.227; Recall 1: 0.730; Accuracy: 0.637; AUROC: 0.478 -> Decision Tree\n",
      "Precision 0: 0.000; Precision 1: 0.817; Recall 0: 0.000; Recall 1: 1.000; Accuracy: 0.817; AUROC: 0.500 -> Multi-layer Perceptron\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0: 0.190; Precision 1: 0.817; Recall 0: 0.091; Recall 1: 0.913; Accuracy: 0.762; AUROC: 0.502 -> AdaBoost\n",
      "Precision 0: 0.206; Precision 1: 0.820; Recall 0: 0.159; Recall 1: 0.862; Accuracy: 0.733; AUROC: 0.511 -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechniqueAgaintTestData(normalize2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
