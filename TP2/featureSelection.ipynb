{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsenteeismAtWork = pd.read_csv('data/train_data.csv', index_col=0)\n",
    "AbsenteeismAtWork['Work load Average/day '] = [x.replace(',', '') for x in AbsenteeismAtWork['Work load Average/day ']]\n",
    "AbsenteeismAtWork['Work load Average/day '] = AbsenteeismAtWork['Work load Average/day '].astype(int)\n",
    "\n",
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformBalanceSelectTrainPredict(featureSelector, model, name):\n",
    "    \n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "    X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "    # Normalizar, discretizar ou standardizar\n",
    "    X_train_transformed, X_test_transformed = discretize(X_train, X_test)\n",
    "    \n",
    "    # Balancear Data Set\n",
    "    X_train_balanced, y_train_balanced = overSampler(X_train_transformed, y_train)\n",
    "    \n",
    "    # Feature Selection\n",
    "    X_train_selected, X_test_selected = featureSelector(X_train_balanced, y_train_balanced, X_test_transformed)\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model.fit(X_train_selected, y_train_balanced)\n",
    "    \n",
    "    # Prever resultados para test set\n",
    "    predicted = model.predict(X_test_selected)\n",
    "    \n",
    "    # Avaliar modelo\n",
    "    evaluateModel(name, y_test, predicted)\n",
    "    return;\n",
    "\n",
    "def evaluateModel(name, y_test, predicted):\n",
    "    print(\"\".join([\"Prec 0: \",'%.3f' % precision_score(y_test,predicted,pos_label=0),\n",
    "                   \"; Prec 1: \",'%.3f' % precision_score(y_test,predicted,pos_label=1),\n",
    "                   \"; Rec 0: \",'%.3f' % recall_score(y_test,predicted,pos_label=0),\n",
    "                   \"; Rec 1: \",'%.3f' % recall_score(y_test,predicted,pos_label=1),\n",
    "                  \"; Acc: \",'%.3f' % accuracy_score(y_test,predicted), \"; -> \" , name]))\n",
    "    return;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XXXXX Up-sample minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xxxx Resample with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xxxx Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "def discretize(X_train, X_test):\n",
    "    featuresToDiscretize = ['Transportation expense', 'Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Hit target', 'Weight', 'Height', 'Body mass index']\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    X_train[featuresToDiscretize] = discretizer.fit_transform(X_train[featuresToDiscretize])\n",
    "    X_test[featuresToDiscretize] = discretizer.transform(X_test[featuresToDiscretize])\n",
    "    return X_train, X_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, GenericUnivariateSelect\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPickedFeatures(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    selected_features_names = list(data.columns[selected_features_index])\n",
    "    return selected_features_names;\n",
    "\n",
    "\n",
    "def getDroppedFeatures(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    dropped_features_names = list(data.columns[dropped_features_index])\n",
    "    return dropped_features_names;\n",
    "\n",
    "\n",
    "def printFeatureSelection(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    selected_features_names = zip(selected_features_index,  list(data.columns[selected_features_index]))\n",
    "    dropped_features_names = zip(dropped_features_index, list(data.columns[dropped_features_index]))\n",
    "\n",
    "    print(\"Features mantidas:\")\n",
    "    for cn in selected_features_names:\n",
    "        print(\"\\t\" + str(cn))\n",
    "\n",
    "    print(\"Features eliminadas:\")\n",
    "    for cn in dropped_features_names:\n",
    "        print(\"\\t\" + str(cn))\n",
    "    return;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectVarianceThreshold(X_train, y_train, X_test):\n",
    "    varianceThreshold_selector = VarianceThreshold()\n",
    "    selector = varianceThreshold_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = varianceThreshold_selector.transform(X_train)\n",
    "    X_test_selected = varianceThreshold_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectKBest_f_classif(X_train, y_train, X_test):\n",
    "    kbest_selector_f_classif = SelectKBest(f_classif, k=12)\n",
    "    selector = kbest_selector_f_classif.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = kbest_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectKBest_chi2(X_train, y_train, X_test):\n",
    "    kbest_selector_chi2 = SelectKBest(chi2, k=12)\n",
    "    selector = kbest_selector_chi2.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_chi2.transform(X_train)\n",
    "    X_test_selected = kbest_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectPercentile_f_classif(X_train, y_train, X_test):\n",
    "    percentile_selector_f_classif = SelectPercentile(f_classif, percentile=10)\n",
    "    selector = percentile_selector_f_classif.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = percentile_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectPercentile_chi2(X_train, y_train, X_test):\n",
    "    percentile_selector_chi2 = SelectPercentile(chi2, percentile=10)\n",
    "    selector = percentile_selector_chi2.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_chi2.transform(X_train)\n",
    "    X_test_selected = percentile_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GenericUnivariateSelect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectGenericUnivariateSelect(X_train, y_train, X_test):\n",
    "    gus_selector = GenericUnivariateSelect(chi2, 'k_best', param=19)\n",
    "    selector = gus_selector.fit(X_train, y_train)\n",
    "    X_train_selected = gus_selector.transform(X_train)\n",
    "    X_test_selected = gus_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeLogReg(X_train, y_train, X_test):\n",
    "    rfe_log_selector = RFE(LogisticRegression(), 12)\n",
    "    selector = rfe_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_log_selector.transform(X_train)\n",
    "    X_test_selected = rfe_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def rfeSVC(X_train, y_train, X_test):\n",
    "    rfe_svc_selector = RFE(SVC(kernel='linear'), 12)\n",
    "    selector = rfe_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfe_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination w/ Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeCvLogReg(X_train, y_train, X_test):\n",
    "    rfecv_log_selector = RFECV(LogisticRegression(), 12)\n",
    "    selector = rfecv_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfecv_log_selector.transform(X_train)\n",
    "    X_test_selected = rfecv_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def rfeCvSVC(X_train, y_train, X_test):\n",
    "    rfecv_svc_selector = RFECV(SVC(kernel='linear'), 12)\n",
    "    selector = rfecv_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfecv_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfecv_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfmLogReg(X_train, y_train, X_test):\n",
    "    sfm_logReg_selector = SelectFromModel(estimator=LogisticRegression())\n",
    "    selector = sfm_logReg_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = sfm_logReg_selector.transform(X_train)\n",
    "    X_test_selected = sfm_logReg_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel and LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfmLcvLogReg(X_train, y_train, X_test):\n",
    "    sfmlcv_logReg_selector = SelectFromModel(LassoCV(),threshold=0.25)\n",
    "    selector = sfmlcv_logReg_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = sfmlcv_logReg_selector.transform(X_train)\n",
    "    X_test_selected = sfmlcv_logReg_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfmL1(X_train, y_train, X_test):\n",
    "    lsvc_selector = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "    selector = lsvc_selector.fit(X_train, y_train)\n",
    "    l1_selector = SelectFromModel(lsvc_selector, prefit=True)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = l1_selector.transform(X_train)\n",
    "    X_test_selected = l1_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfmTree(X_train, y_train, X_test):\n",
    "    tree_selector = ExtraTreesClassifier(n_estimators=50)\n",
    "    selector = tree_selector.fit(X_train, y_train)\n",
    "    sfm_Tree_selector = SelectFromModel(tree_selector, prefit=True)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = sfm_Tree_selector.transform(X_train)\n",
    "    X_test_selected = sfm_Tree_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec 0: 0.187; Prec 1: 0.818; Rec 0: 0.318; Rec 1: 0.689; Acc: 0.621; -> KNeighborsClassifier w/ VarianceThreshold\n",
      "Prec 0: 0.150; Prec 1: 0.810; Rec 0: 0.136; Rec 1: 0.827; Acc: 0.700; -> SVC w/ VarianceThreshold\n",
      "Prec 0: 0.207; Prec 1: 0.829; Rec 0: 0.386; Rec 1: 0.668; Acc: 0.617; -> SVC Linear w/ VarianceThreshold\n",
      "\n",
      "\n",
      "Prec 0: 0.173; Prec 1: 0.812; Rec 0: 0.295; Rec 1: 0.684; Acc: 0.613; -> KNeighborsClassifier w/ KBest FClassif\n",
      "Prec 0: 0.183; Prec 1: 0.816; Rec 0: 0.341; Rec 1: 0.658; Acc: 0.600; -> KNeighborsClassifier w/ KBest Chi2\n",
      "Prec 0: 0.229; Prec 1: 0.835; Rec 0: 0.364; Rec 1: 0.724; Acc: 0.658; -> KNeighborsClassifier w/ Percentile FClassif\n",
      "Prec 0: 0.264; Prec 1: 0.840; Rec 0: 0.318; Rec 1: 0.801; Acc: 0.713; -> KNeighborsClassifier w/ Percentile Chi2\n",
      "Prec 0: 0.206; Prec 1: 0.825; Rec 0: 0.295; Rec 1: 0.745; Acc: 0.662; -> KNeighborsClassifier w/ GUS ---\n",
      "Prec 0: 0.207; Prec 1: 0.820; Rec 0: 0.136; Rec 1: 0.883; Acc: 0.746; -> SVC w/ KBest FClassif\n",
      "Prec 0: 0.158; Prec 1: 0.812; Rec 0: 0.136; Rec 1: 0.837; Acc: 0.708; -> SVC w/ KBest Chi2\n",
      "Prec 0: 0.261; Prec 1: 0.825; Rec 0: 0.136; Rec 1: 0.913; Acc: 0.771; -> SVC w/ Percentile FClassif\n",
      "Prec 0: 0.333; Prec 1: 0.827; Rec 0: 0.114; Rec 1: 0.949; Acc: 0.796; -> SVC w/ Percentile Chi2\n",
      "Prec 0: 0.208; Prec 1: 0.819; Rec 0: 0.114; Rec 1: 0.903; Acc: 0.758; -> SVC w/ GUS ---\n",
      "Prec 0: 0.182; Prec 1: 0.816; Rec 0: 0.227; Rec 1: 0.770; Acc: 0.671; -> SVC Linear w/ KBest FClassif\n",
      "Prec 0: 0.107; Prec 1: 0.807; Rec 0: 0.068; Rec 1: 0.872; Acc: 0.725; -> SVC Linear w/ KBest Chi2\n",
      "Prec 0: 0.375; Prec 1: 0.823; Rec 0: 0.068; Rec 1: 0.974; Acc: 0.808; -> SVC Linear w/ Percentile FClassif\n",
      "Prec 0: 0.375; Prec 1: 0.823; Rec 0: 0.068; Rec 1: 0.974; Acc: 0.808; -> SVC Linear w/ Percentile Chi2\n",
      "Prec 0: 0.241; Prec 1: 0.864; Rec 0: 0.591; Rec 1: 0.582; Acc: 0.583; -> SVC Linear w/ GUS ---\n",
      "\n",
      "\n",
      "Prec 0: 0.202; Prec 1: 0.835; Rec 0: 0.545; Rec 1: 0.515; Acc: 0.521; -> SVC Linear w/ RFE SVC\n",
      "Prec 0: 0.253; Prec 1: 0.859; Rec 0: 0.523; Rec 1: 0.653; Acc: 0.629; -> SVC Linear w/ RFE Cross Validation SVC\n",
      "\n",
      "\n",
      "Prec 0: 0.375; Prec 1: 0.823; Rec 0: 0.068; Rec 1: 0.974; Acc: 0.808; -> Log Reg w/ SelectFromModel and LassoCV\n",
      "Prec 0: 0.196; Prec 1: 0.821; Rec 0: 0.250; Rec 1: 0.770; Acc: 0.675; -> SVC Linear w/ SelectFromModel L1\n",
      "Prec 0: 0.375; Prec 1: 0.823; Rec 0: 0.068; Rec 1: 0.974; Acc: 0.808; -> SVC Linear w/ SelectFromModel Tree\n"
     ]
    }
   ],
   "source": [
    "# Removing features with low variance\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectVarianceThreshold, KNeighborsClassifier(n_neighbors=5), \"KNeighborsClassifier w/ VarianceThreshold\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectVarianceThreshold, SVC(), \"SVC w/ VarianceThreshold\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectVarianceThreshold, SVC(kernel='linear'), \"SVC Linear w/ VarianceThreshold\")\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Univariate feature selection\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectKBest_f_classif, KNeighborsClassifier(n_neighbors=5), \"KNeighborsClassifier w/ KBest FClassif\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectKBest_chi2, KNeighborsClassifier(n_neighbors=5), \"KNeighborsClassifier w/ KBest Chi2\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectPercentile_f_classif, KNeighborsClassifier(n_neighbors=5), \"KNeighborsClassifier w/ Percentile FClassif\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectPercentile_chi2, KNeighborsClassifier(n_neighbors=5), \"KNeighborsClassifier w/ Percentile Chi2\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectGenericUnivariateSelect, KNeighborsClassifier(n_neighbors=5), \"KNeighborsClassifier w/ GUS ---\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectKBest_f_classif, SVC(), \"SVC w/ KBest FClassif\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectKBest_chi2, SVC(), \"SVC w/ KBest Chi2\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectPercentile_f_classif, SVC(), \"SVC w/ Percentile FClassif\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectPercentile_chi2, SVC(), \"SVC w/ Percentile Chi2\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectGenericUnivariateSelect, SVC(), \"SVC w/ GUS ---\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectKBest_f_classif, SVC(kernel='linear'), \"SVC Linear w/ KBest FClassif\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectKBest_chi2, SVC(kernel='linear'), \"SVC Linear w/ KBest Chi2\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectPercentile_f_classif, SVC(kernel='linear'), \"SVC Linear w/ Percentile FClassif\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectPercentile_chi2, SVC(kernel='linear'), \"SVC Linear w/ Percentile Chi2\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( selectGenericUnivariateSelect, SVC(kernel='linear'), \"SVC Linear w/ GUS ---\")\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Recursive feature elimination\n",
    "\n",
    "#TransformBalanceSelectTrainPredict( rfeLogReg,  LogisticRegression(), \"Log Reg w/ RFE LogReg\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( rfeSVC, SVC(kernel='linear'), \"SVC Linear w/ RFE SVC\")\n",
    "\n",
    "#TransformBalanceSelectTrainPredict( rfeCvLogReg, LogisticRegression(), \"SVC Linear w/ RFE Cross Validation LogReg\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( rfeCvSVC, SVC(kernel='linear'), \"SVC Linear w/ RFE Cross Validation SVC\")\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Feature selection using SelectFromModel\n",
    "\n",
    "#TransformBalanceSelectTrainPredict( sfmLogReg, LogisticRegression(), \"Log Reg w/ SelectFromModel LogReg\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( sfmLcvLogReg, LogisticRegression(), \"Log Reg w/ SelectFromModel and LassoCV\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( sfmL1, SVC(kernel='linear'), \"SVC Linear w/ SelectFromModel L1\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( sfmTree, SVC(kernel='linear'), \"SVC Linear w/ SelectFromModel Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
