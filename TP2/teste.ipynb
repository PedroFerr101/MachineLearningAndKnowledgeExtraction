{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsenteeismAtWork = pd.read_csv('data/train_data.csv', index_col=0)\n",
    "AbsenteeismAtWork['Work load Average/day '] = [x.replace(',', '') for x in AbsenteeismAtWork['Work load Average/day ']]\n",
    "AbsenteeismAtWork['Work load Average/day '] = AbsenteeismAtWork['Work load Average/day '].astype(int)\n",
    "\n",
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformBalanceSelectTrainPredict( transformer, balancer, featureSelector, model, name):\n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "    X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "    # Normalizar, discretizar ou standardizar\n",
    "    X_train_transformed, X_test_transformed = transformer(X_train, X_test)\n",
    "    \n",
    "    # Balancear Data Set\n",
    "    X_train_balanced, y_train_balanced = balancer(X_train_transformed, y_train)\n",
    "    \n",
    "    # Feature Selection\n",
    "    X_train_selected, X_test_selected = featureSelector(X_train_balanced, y_train_balanced, X_test_transformed)\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model.fit(X_train_selected, y_train_balanced)\n",
    "    \n",
    "    # Prever resultados para test set\n",
    "    predicted = model.predict(X_test_selected)\n",
    "    \n",
    "    # Avaliar modelo\n",
    "    print(str(accuracy_score(y_test, predicted)))\n",
    "    print(classification_report(y_test, predicted))\n",
    "    \n",
    "    return;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-sample minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample with replacement\n",
    "\n",
    "Método mais simples que consiste em replicar aleatoriamente (com reposição) dados da classe minoritária até atingir ratio de 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "def smoteSampler(X_train, y_train):\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    X_balanced, y_train = smote.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sample majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "def underSampler(X_train, y_train):\n",
    "    rus = RandomUnderSampler()\n",
    "    X_balanced, y_train = rus.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "def tomekSampler(X_train, y_train):\n",
    "    tl = TomekLinks(sampling_strategy='majority')\n",
    "    X_balanced, y_train = tl.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "def centroidSampler(X_train, y_train):\n",
    "    cc = ClusterCentroids(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "def discretize(X_train, X_test):\n",
    "    featuresToDiscretize = ['Transportation expense', 'Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Hit target', 'Weight', 'Height', 'Body mass index']\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    X_train[featuresToDiscretize] = discretizer.fit_transform(X_train[featuresToDiscretize])\n",
    "    X_test[featuresToDiscretize] = discretizer.transform(X_test[featuresToDiscretize])\n",
    "    return X_train, X_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scalerFunc(X_train, X_test): \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    X_test_transformed = scaler.transform( X_test )\n",
    "    return scaled_data, X_test_transformed;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPickedFeatures(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    selected_features_names = list(data.columns[selected_features_index])\n",
    "    return selected_features_names;\n",
    "\n",
    "\n",
    "def getDroppedFeatures(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    dropped_features_names = list(data.columns[dropped_features_index])\n",
    "    return dropped_features_names;\n",
    "\n",
    "\n",
    "def printFeatureSelection(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    selected_features_names = zip(selected_features_index,  list(data.columns[selected_features_index]))\n",
    "    dropped_features_names = zip(dropped_features_index, list(data.columns[dropped_features_index]))\n",
    "\n",
    "    print(\"Features mantidas:\")\n",
    "    for cn in selected_features_names:\n",
    "        print(\"\\t\" + str(cn))\n",
    "\n",
    "    print(\"Features eliminadas:\")\n",
    "    for cn in dropped_features_names:\n",
    "        print(\"\\t\" + str(cn))\n",
    "    return;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKBest (Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def selectKBest(X_train, y_train, X_test):\n",
    "    kbest_selector = SelectKBest(f_classif, k=12)\n",
    "    selector = kbest_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = kbest_selector.transform(X_train)\n",
    "    X_test_selected = kbest_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination (Wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def rfeLogReg(X_train, y_train, X_test):\n",
    "    rfe_log_selector = RFE(LogisticRegression(), 12)\n",
    "    rfe_log_selector = rfe_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_log_selector.transform(X_train)\n",
    "    X_test_selected = rfe_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def rfeSVC(X_train, y_train, X_test):\n",
    "    rfe_svc_selector = RFE(SVC(kernel='linear'), 12)\n",
    "    rfe_svc_selector = rfe_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfe_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.34      0.23        44\n",
      "           1       0.81      0.64      0.71       196\n",
      "\n",
      "    accuracy                           0.58       240\n",
      "   macro avg       0.49      0.49      0.47       240\n",
      "weighted avg       0.69      0.58      0.63       240\n",
      "\n",
      "0.675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.41      0.32        44\n",
      "           1       0.85      0.73      0.79       196\n",
      "\n",
      "    accuracy                           0.68       240\n",
      "   macro avg       0.55      0.57      0.55       240\n",
      "weighted avg       0.74      0.68      0.70       240\n",
      "\n",
      "0.6083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.36      0.25        44\n",
      "           1       0.82      0.66      0.73       196\n",
      "\n",
      "    accuracy                           0.61       240\n",
      "   macro avg       0.51      0.51      0.49       240\n",
      "weighted avg       0.71      0.61      0.65       240\n",
      "\n",
      "0.7666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.11      0.15        44\n",
      "           1       0.82      0.91      0.86       196\n",
      "\n",
      "    accuracy                           0.77       240\n",
      "   macro avg       0.52      0.51      0.51       240\n",
      "weighted avg       0.71      0.77      0.73       240\n",
      "\n",
      "0.6208333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32        44\n",
      "           1       0.85      0.65      0.74       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.54      0.57      0.53       240\n",
      "weighted avg       0.74      0.62      0.66       240\n",
      "\n",
      "0.7458333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.14      0.16        44\n",
      "           1       0.82      0.88      0.85       196\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.51      0.51      0.51       240\n",
      "weighted avg       0.71      0.75      0.72       240\n",
      "\n",
      "0.6583333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.27      0.23        44\n",
      "           1       0.82      0.74      0.78       196\n",
      "\n",
      "    accuracy                           0.66       240\n",
      "   macro avg       0.51      0.51      0.50       240\n",
      "weighted avg       0.71      0.66      0.68       240\n",
      "\n",
      "0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.43      0.27        44\n",
      "           1       0.83      0.61      0.70       196\n",
      "\n",
      "    accuracy                           0.57       240\n",
      "   macro avg       0.51      0.52      0.49       240\n",
      "weighted avg       0.71      0.57      0.62       240\n",
      "\n",
      "0.7916666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.11      0.17        44\n",
      "           1       0.83      0.94      0.88       196\n",
      "\n",
      "    accuracy                           0.79       240\n",
      "   macro avg       0.57      0.53      0.52       240\n",
      "weighted avg       0.73      0.79      0.75       240\n",
      "\n",
      "0.5958333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.39      0.26        44\n",
      "           1       0.82      0.64      0.72       196\n",
      "\n",
      "    accuracy                           0.60       240\n",
      "   macro avg       0.51      0.51      0.49       240\n",
      "weighted avg       0.71      0.60      0.64       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6208333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.50      0.33        44\n",
      "           1       0.85      0.65      0.74       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.55      0.57      0.53       240\n",
      "weighted avg       0.74      0.62      0.66       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7458333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.20      0.23        44\n",
      "           1       0.83      0.87      0.85       196\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.54      0.54      0.54       240\n",
      "weighted avg       0.72      0.75      0.73       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.48      0.31        44\n",
      "           1       0.85      0.65      0.73       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.54      0.56      0.52       240\n",
      "weighted avg       0.73      0.62      0.66       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7958333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.18      0.25        44\n",
      "           1       0.84      0.93      0.88       196\n",
      "\n",
      "    accuracy                           0.80       240\n",
      "   macro avg       0.61      0.56      0.56       240\n",
      "weighted avg       0.75      0.80      0.77       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.66      0.29        44\n",
      "           1       0.83      0.36      0.50       196\n",
      "\n",
      "    accuracy                           0.42       240\n",
      "   macro avg       0.51      0.51      0.40       240\n",
      "weighted avg       0.71      0.42      0.46       240\n",
      "\n",
      "0.6375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.43      0.30        44\n",
      "           1       0.84      0.68      0.75       196\n",
      "\n",
      "    accuracy                           0.64       240\n",
      "   macro avg       0.54      0.56      0.53       240\n",
      "weighted avg       0.73      0.64      0.67       240\n",
      "\n",
      "0.7125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.20      0.21        44\n",
      "           1       0.82      0.83      0.82       196\n",
      "\n",
      "    accuracy                           0.71       240\n",
      "   macro avg       0.52      0.52      0.52       240\n",
      "weighted avg       0.71      0.71      0.71       240\n",
      "\n",
      "0.6375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.45      0.31        44\n",
      "           1       0.85      0.68      0.75       196\n",
      "\n",
      "    accuracy                           0.64       240\n",
      "   macro avg       0.54      0.57      0.53       240\n",
      "weighted avg       0.74      0.64      0.67       240\n",
      "\n",
      "0.8083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.07      0.12        44\n",
      "           1       0.82      0.97      0.89       196\n",
      "\n",
      "    accuracy                           0.81       240\n",
      "   macro avg       0.60      0.52      0.50       240\n",
      "weighted avg       0.74      0.81      0.75       240\n",
      "\n",
      "0.475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.61      0.30        44\n",
      "           1       0.84      0.44      0.58       196\n",
      "\n",
      "    accuracy                           0.48       240\n",
      "   macro avg       0.52      0.53      0.44       240\n",
      "weighted avg       0.72      0.47      0.53       240\n",
      "\n",
      "0.6416666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.27      0.22        44\n",
      "           1       0.82      0.72      0.77       196\n",
      "\n",
      "    accuracy                           0.64       240\n",
      "   macro avg       0.50      0.50      0.49       240\n",
      "weighted avg       0.70      0.64      0.67       240\n",
      "\n",
      "0.5958333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.25      0.18        44\n",
      "           1       0.80      0.67      0.73       196\n",
      "\n",
      "    accuracy                           0.60       240\n",
      "   macro avg       0.47      0.46      0.46       240\n",
      "weighted avg       0.68      0.60      0.63       240\n",
      "\n",
      "0.5458333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.39      0.24        44\n",
      "           1       0.81      0.58      0.68       196\n",
      "\n",
      "    accuracy                           0.55       240\n",
      "   macro avg       0.49      0.48      0.46       240\n",
      "weighted avg       0.69      0.55      0.60       240\n",
      "\n",
      "0.7833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        44\n",
      "           1       0.82      0.94      0.88       196\n",
      "\n",
      "    accuracy                           0.78       240\n",
      "   macro avg       0.54      0.51      0.50       240\n",
      "weighted avg       0.72      0.78      0.74       240\n",
      "\n",
      "0.5958333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.34      0.24        44\n",
      "           1       0.82      0.65      0.73       196\n",
      "\n",
      "    accuracy                           0.60       240\n",
      "   macro avg       0.50      0.50      0.48       240\n",
      "weighted avg       0.70      0.60      0.64       240\n",
      "\n",
      "0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.23      0.19        44\n",
      "           1       0.81      0.74      0.78       196\n",
      "\n",
      "    accuracy                           0.65       240\n",
      "   macro avg       0.49      0.49      0.48       240\n",
      "weighted avg       0.69      0.65      0.67       240\n",
      "\n",
      "0.6458333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.25      0.21        44\n",
      "           1       0.81      0.73      0.77       196\n",
      "\n",
      "    accuracy                           0.65       240\n",
      "   macro avg       0.49      0.49      0.49       240\n",
      "weighted avg       0.70      0.65      0.67       240\n",
      "\n",
      "0.7375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.14      0.16        44\n",
      "           1       0.82      0.87      0.84       196\n",
      "\n",
      "    accuracy                           0.74       240\n",
      "   macro avg       0.51      0.50      0.50       240\n",
      "weighted avg       0.70      0.74      0.72       240\n",
      "\n",
      "0.8083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.07      0.12        44\n",
      "           1       0.82      0.97      0.89       196\n",
      "\n",
      "    accuracy                           0.81       240\n",
      "   macro avg       0.60      0.52      0.50       240\n",
      "weighted avg       0.74      0.81      0.75       240\n",
      "\n",
      "0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.20      0.18        44\n",
      "           1       0.81      0.75      0.78       196\n",
      "\n",
      "    accuracy                           0.65       240\n",
      "   macro avg       0.48      0.48      0.48       240\n",
      "weighted avg       0.69      0.65      0.67       240\n",
      "\n",
      "0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.32      0.28        44\n",
      "           1       0.84      0.79      0.81       196\n",
      "\n",
      "    accuracy                           0.70       240\n",
      "   macro avg       0.54      0.55      0.55       240\n",
      "weighted avg       0.73      0.70      0.71       240\n",
      "\n",
      "0.6166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.48      0.31        44\n",
      "           1       0.85      0.65      0.73       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.54      0.56      0.52       240\n",
      "weighted avg       0.73      0.62      0.66       240\n",
      "\n",
      "0.6166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.45      0.30        44\n",
      "           1       0.84      0.65      0.74       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.53      0.55      0.52       240\n",
      "weighted avg       0.73      0.62      0.66       240\n",
      "\n",
      "0.7958333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.16      0.22        44\n",
      "           1       0.83      0.94      0.88       196\n",
      "\n",
      "    accuracy                           0.80       240\n",
      "   macro avg       0.60      0.55      0.55       240\n",
      "weighted avg       0.75      0.80      0.76       240\n",
      "\n",
      "0.5458333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.50      0.29        44\n",
      "           1       0.83      0.56      0.67       196\n",
      "\n",
      "    accuracy                           0.55       240\n",
      "   macro avg       0.52      0.53      0.48       240\n",
      "weighted avg       0.72      0.55      0.60       240\n",
      "\n",
      "0.6458333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.39      0.29        44\n",
      "           1       0.84      0.70      0.76       196\n",
      "\n",
      "    accuracy                           0.65       240\n",
      "   macro avg       0.53      0.55      0.53       240\n",
      "weighted avg       0.72      0.65      0.68       240\n",
      "\n",
      "0.6791666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.45      0.34        44\n",
      "           1       0.86      0.73      0.79       196\n",
      "\n",
      "    accuracy                           0.68       240\n",
      "   macro avg       0.57      0.59      0.56       240\n",
      "weighted avg       0.75      0.68      0.71       240\n",
      "\n",
      "0.5875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.43      0.28        44\n",
      "           1       0.83      0.62      0.71       196\n",
      "\n",
      "    accuracy                           0.59       240\n",
      "   macro avg       0.52      0.53      0.49       240\n",
      "weighted avg       0.72      0.59      0.63       240\n",
      "\n",
      "0.8083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.07      0.12        44\n",
      "           1       0.82      0.97      0.89       196\n",
      "\n",
      "    accuracy                           0.81       240\n",
      "   macro avg       0.60      0.52      0.50       240\n",
      "weighted avg       0.74      0.81      0.75       240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.55      0.30        44\n",
      "           1       0.84      0.52      0.64       196\n",
      "\n",
      "    accuracy                           0.53       240\n",
      "   macro avg       0.52      0.53      0.47       240\n",
      "weighted avg       0.72      0.53      0.58       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transformer : discretize , scalerFunc\n",
    "# Balancer: overSampler , smoteSampler , underSampler , tomekSampler , centroidSampler\n",
    "# FeatureSelector : selectKBest , rfeLogReg , rfeSVC\n",
    "\n",
    "TransformBalanceSelectTrainPredict( discretize, overSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, smoteSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, underSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, tomekSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, centroidSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "\n",
    "TransformBalanceSelectTrainPredict( discretize, overSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, smoteSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, underSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, tomekSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, centroidSampler, selectKBest, SVC(), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict( discretize, overSampler, rfeLogReg,  LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, smoteSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, underSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, tomekSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, centroidSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict( discretize, overSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, smoteSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, underSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, tomekSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict( discretize, centroidSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, overSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, smoteSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, underSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, tomekSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, centroidSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, overSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, smoteSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, underSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, tomekSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, centroidSampler, selectKBest, SVC(), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, overSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, smoteSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, underSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, tomekSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, centroidSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, overSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, smoteSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, underSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, tomekSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict( scalerFunc, centroidSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Abordagem com bagging através de random forests para superar problema de dataset desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.11      0.16        44\n",
      "           1       0.82      0.93      0.88       196\n",
      "\n",
      "    accuracy                           0.78       240\n",
      "   macro avg       0.55      0.52      0.52       240\n",
      "weighted avg       0.72      0.78      0.74       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "target = AbsenteeismAtWork['Absent']\n",
    "data = AbsenteeismAtWork.drop('Absent', 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform( data )\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(data, target)\n",
    " \n",
    "pred = clf.predict(X_test_scaled)\n",
    " \n",
    "print( accuracy_score(y_test, pred) )\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-Sensitive Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.27      0.20        44\n",
      "           1       0.81      0.68      0.74       196\n",
      "\n",
      "    accuracy                           0.61       240\n",
      "   macro avg       0.48      0.48      0.47       240\n",
      "weighted avg       0.69      0.61      0.64       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svc = SVC(kernel='linear', \n",
    "            class_weight='balanced', \n",
    "            probability=True)\n",
    "\n",
    "svc.fit(selected, target)\n",
    "\n",
    "predSvc = svc.predict(X_test_selected)\n",
    " \n",
    "print( accuracy_score(y_test, predSvc) )\n",
    "print(classification_report(y_test, predSvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.14      0.16        44\n",
      "           1       0.82      0.87      0.84       196\n",
      "\n",
      "    accuracy                           0.74       240\n",
      "   macro avg       0.51      0.50      0.50       240\n",
      "weighted avg       0.70      0.74      0.72       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "target = AbsenteeismAtWork['Absent']\n",
    "data = AbsenteeismAtWork.drop('Absent', 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform( data )\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "\n",
    "\n",
    "classifier.fit(data, target)\n",
    "\n",
    "predAda = classifier.predict(X_test_scaled)\n",
    " \n",
    "print( accuracy_score(y_test, predAda) )\n",
    "print(classification_report(y_test, predAda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
