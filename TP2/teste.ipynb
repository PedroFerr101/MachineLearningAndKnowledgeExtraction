{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsenteeismAtWork = pd.read_csv('data/train_data.csv', index_col=0)\n",
    "AbsenteeismAtWork['Work load Average/day '] = [x.replace(',', '.') for x in AbsenteeismAtWork['Work load Average/day ']]\n",
    "AbsenteeismAtWork['Work load Average/day '] = AbsenteeismAtWork['Work load Average/day '].astype(float)\n",
    "\n",
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, transformer, balancer, featureSelector, model, name):\n",
    "    # Normalizar, discretizar ou standardizar\n",
    "    X_train_transformed, X_test_transformed = transformer(X_train, X_test)\n",
    "    \n",
    "    # Balancear Data Set\n",
    "    X_train_balanced, y_train_balanced = balancer(X_train_transformed, y_train)\n",
    "    \n",
    "    # Feature Selection\n",
    "    X_train_selected, X_test_selected = featureSelector(X_train_balanced, y_train_balanced, X_test_transformed)\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model.fit(X_train_selected, y_train_balanced)\n",
    "    \n",
    "    # Prever resultados para test set\n",
    "    predicted = model.predict(X_test_selected)\n",
    "    \n",
    "    # Avaliar modelo\n",
    "    print(str(accuracy_score(y_test, predicted)))\n",
    "    print(classification_report(y_test, predicted))\n",
    "    \n",
    "    return;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-sample minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample with replacement\n",
    "\n",
    "Método mais simples que consiste em replicar aleatoriamente (com reposição) dados da classe minoritária até atingir ratio de 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "def smoteSampler(X_train, y_train):\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    X_balanced, y_train = smote.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sample majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "def underSampler(X_train, y_train):\n",
    "    rus = RandomUnderSampler()\n",
    "    X_balanced, y_train = rus.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "def tomekSampler(X_train, y_train):\n",
    "    tl = TomekLinks(sampling_strategy='majority')\n",
    "    X_balanced, y_train = tl.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "def centroidSampler(X_train, y_train):\n",
    "    cc = ClusterCentroids(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "def discretize(X_train, X_test):\n",
    "    featuresToDiscretize = ['Transportation expense', 'Distance from Residence to Work', 'Service time', 'Age', 'Work load Average/day ', 'Hit target', 'Weight', 'Height', 'Body mass index']\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    X_train[featuresToDiscretize] = discretizer.fit_transform(X_train[featuresToDiscretize])\n",
    "    X_test[featuresToDiscretize] = discretizer.transform(X_test[featuresToDiscretize])\n",
    "    return X_train, X_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scalerFunc(X_train, X_test): \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    X_test_transformed = scaler.transform( X_test )\n",
    "    return scaled_data, X_test_transformed;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPickedFeatures(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    selected_features_names = list(data.columns[selected_features_index])\n",
    "    return selected_features_names;\n",
    "\n",
    "\n",
    "def getDroppedFeatures(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    dropped_features_names = list(data.columns[dropped_features_index])\n",
    "    return dropped_features_names;\n",
    "\n",
    "\n",
    "def printFeatureSelection(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    selected_features_names = zip(selected_features_index,  list(data.columns[selected_features_index]))\n",
    "    dropped_features_names = zip(dropped_features_index, list(data.columns[dropped_features_index]))\n",
    "\n",
    "    print(\"Features mantidas:\")\n",
    "    for cn in selected_features_names:\n",
    "        print(\"\\t\" + str(cn))\n",
    "\n",
    "    print(\"Features eliminadas:\")\n",
    "    for cn in dropped_features_names:\n",
    "        print(\"\\t\" + str(cn))\n",
    "    return;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKBest (Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def selectKBest(X_train, y_train, X_test):\n",
    "    kbest_selector = SelectKBest(f_classif, k=12)\n",
    "    selector = kbest_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = kbest_selector.transform(X_train)\n",
    "    X_test_selected = kbest_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination (Wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def rfeLogReg(X_train, y_train, X_test):\n",
    "    rfe_log_selector = RFE(LogisticRegression(), 12)\n",
    "    rfe_log_selector = rfe_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_log_selector.transform(X_train)\n",
    "    X_test_selected = rfe_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def rfeSVC(X_train, y_train, X_test):\n",
    "    rfe_svc_selector = RFE(SVC(kernel='linear'), 12)\n",
    "    rfe_svc_selector = rfe_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfe_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Reason for absence  Month of absence  Day of the week  Seasons  \\\n",
      "ID                                                                    \n",
      "1                    26                 7                3        1   \n",
      "2                     0                 7                3        1   \n",
      "3                    23                 7                4        1   \n",
      "4                     7                 7                5        1   \n",
      "5                    23                 7                5        1   \n",
      "..                  ...               ...              ...      ...   \n",
      "496                  28                 9                3        1   \n",
      "497                  28                 9                3        1   \n",
      "498                  28                 9                3        1   \n",
      "499                  23                 9                3        1   \n",
      "500                  28                 9                5        1   \n",
      "\n",
      "     Transportation expense  Distance from Residence to Work  Service time  \\\n",
      "ID                                                                           \n",
      "1                       289                               36            13   \n",
      "2                       118                               13            18   \n",
      "3                       179                               51            18   \n",
      "4                       279                                5            14   \n",
      "5                       289                               36            13   \n",
      "..                      ...                              ...           ...   \n",
      "496                     246                               25            16   \n",
      "497                     246                               25            16   \n",
      "498                     118                               10            10   \n",
      "499                     155                               12            14   \n",
      "500                     291                               31            12   \n",
      "\n",
      "     Age  Work load Average/day   Hit target  Disciplinary failure  Education  \\\n",
      "ID                                                                              \n",
      "1     33                 239.554          97                     0          1   \n",
      "2     50                 239.554          97                     1          1   \n",
      "3     38                 239.554          97                     0          1   \n",
      "4     39                 239.554          97                     0          1   \n",
      "5     33                 239.554          97                     0          1   \n",
      "..   ...                     ...         ...                   ...        ...   \n",
      "496   41                 261.756          87                     0          1   \n",
      "497   41                 261.756          87                     0          1   \n",
      "498   37                 261.756          87                     0          1   \n",
      "499   34                 261.756          87                     0          1   \n",
      "500   40                 261.756          87                     0          1   \n",
      "\n",
      "     Son  Social drinker  Social smoker  Pet  Weight  Height  Body mass index  \n",
      "ID                                                                             \n",
      "1      2               1              0    1      90     172               30  \n",
      "2      1               1              0    0      98     178               31  \n",
      "3      0               1              0    0      89     170               31  \n",
      "4      2               1              1    0      68     168               24  \n",
      "5      2               1              0    1      90     172               30  \n",
      "..   ...             ...            ...  ...     ...     ...              ...  \n",
      "496    0               1              0    0      67     170               23  \n",
      "497    0               1              0    0      67     170               23  \n",
      "498    0               0              0    0      83     172               28  \n",
      "499    2               1              0    0      95     196               25  \n",
      "500    1               1              0    1      73     171               25  \n",
      "\n",
      "[500 rows x 19 columns]\n",
      "0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.36      0.26        44\n",
      "           1       0.83      0.68      0.75       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.52      0.52      0.51       240\n",
      "weighted avg       0.71      0.62      0.66       240\n",
      "\n",
      "0.525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.52      0.29        44\n",
      "           1       0.83      0.53      0.64       196\n",
      "\n",
      "    accuracy                           0.53       240\n",
      "   macro avg       0.51      0.52      0.47       240\n",
      "weighted avg       0.71      0.53      0.58       240\n",
      "\n",
      "0.6208333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.32      0.24        44\n",
      "           1       0.82      0.69      0.75       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.50      0.50      0.49       240\n",
      "weighted avg       0.70      0.62      0.65       240\n",
      "\n",
      "0.7416666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.18      0.21        44\n",
      "           1       0.83      0.87      0.85       196\n",
      "\n",
      "    accuracy                           0.74       240\n",
      "   macro avg       0.53      0.52      0.53       240\n",
      "weighted avg       0.72      0.74      0.73       240\n",
      "\n",
      "0.6083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.41      0.28        44\n",
      "           1       0.83      0.65      0.73       196\n",
      "\n",
      "    accuracy                           0.61       240\n",
      "   macro avg       0.52      0.53      0.50       240\n",
      "weighted avg       0.72      0.61      0.65       240\n",
      "\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.11      0.14        44\n",
      "           1       0.82      0.89      0.85       196\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.51      0.50      0.50       240\n",
      "weighted avg       0.70      0.75      0.72       240\n",
      "\n",
      "0.675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.27      0.24        44\n",
      "           1       0.82      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.68       240\n",
      "   macro avg       0.52      0.52      0.51       240\n",
      "weighted avg       0.71      0.68      0.69       240\n",
      "\n",
      "0.725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.14      0.15        44\n",
      "           1       0.82      0.86      0.84       196\n",
      "\n",
      "    accuracy                           0.73       240\n",
      "   macro avg       0.50      0.50      0.49       240\n",
      "weighted avg       0.70      0.72      0.71       240\n",
      "\n",
      "0.7916666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.11      0.17        44\n",
      "           1       0.83      0.94      0.88       196\n",
      "\n",
      "    accuracy                           0.79       240\n",
      "   macro avg       0.57      0.53      0.52       240\n",
      "weighted avg       0.73      0.79      0.75       240\n",
      "\n",
      "0.5666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.41      0.26        44\n",
      "           1       0.82      0.60      0.69       196\n",
      "\n",
      "    accuracy                           0.57       240\n",
      "   macro avg       0.50      0.51      0.48       240\n",
      "weighted avg       0.70      0.57      0.61       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6708333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.27      0.23        44\n",
      "           1       0.82      0.76      0.79       196\n",
      "\n",
      "    accuracy                           0.67       240\n",
      "   macro avg       0.51      0.52      0.51       240\n",
      "weighted avg       0.71      0.67      0.69       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.30      0.27        44\n",
      "           1       0.84      0.81      0.82       196\n",
      "\n",
      "    accuracy                           0.71       240\n",
      "   macro avg       0.55      0.55      0.55       240\n",
      "weighted avg       0.73      0.71      0.72       240\n",
      "\n",
      "0.6375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.32      0.24        44\n",
      "           1       0.82      0.71      0.76       196\n",
      "\n",
      "    accuracy                           0.64       240\n",
      "   macro avg       0.51      0.51      0.50       240\n",
      "weighted avg       0.71      0.64      0.67       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7958333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.18      0.25        44\n",
      "           1       0.84      0.93      0.88       196\n",
      "\n",
      "    accuracy                           0.80       240\n",
      "   macro avg       0.61      0.56      0.56       240\n",
      "weighted avg       0.75      0.80      0.77       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.64      0.30        44\n",
      "           1       0.83      0.41      0.55       196\n",
      "\n",
      "    accuracy                           0.45       240\n",
      "   macro avg       0.51      0.52      0.42       240\n",
      "weighted avg       0.72      0.45      0.50       240\n",
      "\n",
      "0.6166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.48      0.31        44\n",
      "           1       0.85      0.65      0.73       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.54      0.56      0.52       240\n",
      "weighted avg       0.73      0.62      0.66       240\n",
      "\n",
      "0.6125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.32      0.23        44\n",
      "           1       0.82      0.68      0.74       196\n",
      "\n",
      "    accuracy                           0.61       240\n",
      "   macro avg       0.50      0.50      0.49       240\n",
      "weighted avg       0.70      0.61      0.65       240\n",
      "\n",
      "0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.52      0.34        44\n",
      "           1       0.86      0.65      0.74       196\n",
      "\n",
      "    accuracy                           0.62       240\n",
      "   macro avg       0.55      0.59      0.54       240\n",
      "weighted avg       0.75      0.62      0.67       240\n",
      "\n",
      "0.8083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.07      0.12        44\n",
      "           1       0.82      0.97      0.89       196\n",
      "\n",
      "    accuracy                           0.81       240\n",
      "   macro avg       0.60      0.52      0.50       240\n",
      "weighted avg       0.74      0.81      0.75       240\n",
      "\n",
      "0.38333333333333336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.73      0.30        44\n",
      "           1       0.83      0.31      0.45       196\n",
      "\n",
      "    accuracy                           0.38       240\n",
      "   macro avg       0.51      0.52      0.37       240\n",
      "weighted avg       0.72      0.38      0.42       240\n",
      "\n",
      "0.5416666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.66      0.35        44\n",
      "           1       0.87      0.52      0.65       196\n",
      "\n",
      "    accuracy                           0.54       240\n",
      "   macro avg       0.55      0.59      0.50       240\n",
      "weighted avg       0.75      0.54      0.59       240\n",
      "\n",
      "0.5875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.43      0.28        44\n",
      "           1       0.83      0.62      0.71       196\n",
      "\n",
      "    accuracy                           0.59       240\n",
      "   macro avg       0.52      0.53      0.49       240\n",
      "weighted avg       0.72      0.59      0.63       240\n",
      "\n",
      "0.5583333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.59      0.33        44\n",
      "           1       0.86      0.55      0.67       196\n",
      "\n",
      "    accuracy                           0.56       240\n",
      "   macro avg       0.54      0.57      0.50       240\n",
      "weighted avg       0.74      0.56      0.61       240\n",
      "\n",
      "0.7541666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.07      0.09        44\n",
      "           1       0.81      0.91      0.86       196\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.48      0.49      0.48       240\n",
      "weighted avg       0.69      0.75      0.72       240\n",
      "\n",
      "0.5666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.41      0.26        44\n",
      "           1       0.82      0.60      0.69       196\n",
      "\n",
      "    accuracy                           0.57       240\n",
      "   macro avg       0.50      0.51      0.48       240\n",
      "weighted avg       0.70      0.57      0.61       240\n",
      "\n",
      "0.6583333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.25      0.21        44\n",
      "           1       0.82      0.75      0.78       196\n",
      "\n",
      "    accuracy                           0.66       240\n",
      "   macro avg       0.50      0.50      0.50       240\n",
      "weighted avg       0.70      0.66      0.68       240\n",
      "\n",
      "0.6541666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.23      0.19        44\n",
      "           1       0.81      0.75      0.78       196\n",
      "\n",
      "    accuracy                           0.65       240\n",
      "   macro avg       0.49      0.49      0.49       240\n",
      "weighted avg       0.69      0.65      0.67       240\n",
      "\n",
      "0.5708333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.34      0.23        44\n",
      "           1       0.81      0.62      0.70       196\n",
      "\n",
      "    accuracy                           0.57       240\n",
      "   macro avg       0.49      0.48      0.46       240\n",
      "weighted avg       0.69      0.57      0.62       240\n",
      "\n",
      "0.8083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.07      0.12        44\n",
      "           1       0.82      0.97      0.89       196\n",
      "\n",
      "    accuracy                           0.81       240\n",
      "   macro avg       0.60      0.52      0.50       240\n",
      "weighted avg       0.74      0.81      0.75       240\n",
      "\n",
      "0.5666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.43      0.27        44\n",
      "           1       0.82      0.60      0.69       196\n",
      "\n",
      "    accuracy                           0.57       240\n",
      "   macro avg       0.51      0.51      0.48       240\n",
      "weighted avg       0.71      0.57      0.61       240\n",
      "\n",
      "0.6041666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.50      0.32        44\n",
      "           1       0.85      0.63      0.72       196\n",
      "\n",
      "    accuracy                           0.60       240\n",
      "   macro avg       0.54      0.56      0.52       240\n",
      "weighted avg       0.74      0.60      0.65       240\n",
      "\n",
      "0.4583333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.70      0.32        44\n",
      "           1       0.86      0.40      0.55       196\n",
      "\n",
      "    accuracy                           0.46       240\n",
      "   macro avg       0.53      0.55      0.44       240\n",
      "weighted avg       0.74      0.46      0.51       240\n",
      "\n",
      "0.5166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.59      0.31        44\n",
      "           1       0.84      0.50      0.63       196\n",
      "\n",
      "    accuracy                           0.52       240\n",
      "   macro avg       0.53      0.55      0.47       240\n",
      "weighted avg       0.73      0.52      0.57       240\n",
      "\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.23      0.25        44\n",
      "           1       0.83      0.87      0.85       196\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.56      0.55      0.55       240\n",
      "weighted avg       0.73      0.75      0.74       240\n",
      "\n",
      "0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.55      0.31        44\n",
      "           1       0.84      0.55      0.67       196\n",
      "\n",
      "    accuracy                           0.55       240\n",
      "   macro avg       0.53      0.55      0.49       240\n",
      "weighted avg       0.73      0.55      0.60       240\n",
      "\n",
      "0.5791666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.59      0.34        44\n",
      "           1       0.86      0.58      0.69       196\n",
      "\n",
      "    accuracy                           0.58       240\n",
      "   macro avg       0.55      0.58      0.52       240\n",
      "weighted avg       0.75      0.58      0.63       240\n",
      "\n",
      "0.5458333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.55      0.31        44\n",
      "           1       0.84      0.55      0.66       196\n",
      "\n",
      "    accuracy                           0.55       240\n",
      "   macro avg       0.53      0.55      0.48       240\n",
      "weighted avg       0.73      0.55      0.60       240\n",
      "\n",
      "0.5458333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.59      0.32        44\n",
      "           1       0.85      0.54      0.66       196\n",
      "\n",
      "    accuracy                           0.55       240\n",
      "   macro avg       0.54      0.56      0.49       240\n",
      "weighted avg       0.74      0.55      0.60       240\n",
      "\n",
      "0.8083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.07      0.12        44\n",
      "           1       0.82      0.97      0.89       196\n",
      "\n",
      "    accuracy                           0.81       240\n",
      "   macro avg       0.60      0.52      0.50       240\n",
      "weighted avg       0.74      0.81      0.75       240\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.52      0.30        44\n",
      "           1       0.84      0.56      0.67       196\n",
      "\n",
      "    accuracy                           0.55       240\n",
      "   macro avg       0.52      0.54      0.48       240\n",
      "weighted avg       0.72      0.55      0.60       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transformer : discretize , scalerFunc\n",
    "# Balancer: overSampler , smoteSampler , underSampler , tomekSampler , centroidSampler\n",
    "# FeatureSelector : selectKBest , rfeLogReg , rfeSVC\n",
    "\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, overSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, smoteSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, underSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, tomekSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, centroidSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, overSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, smoteSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, underSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, tomekSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, centroidSampler, selectKBest, SVC(), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, overSampler, rfeLogReg,  LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, smoteSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, underSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, tomekSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, centroidSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, overSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, smoteSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, underSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, tomekSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, discretize, centroidSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, overSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, smoteSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, underSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, tomekSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, centroidSampler, selectKBest, KNeighborsClassifier(n_neighbors=5), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, overSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, smoteSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, underSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, tomekSampler, selectKBest, SVC(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, centroidSampler, selectKBest, SVC(), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, overSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, smoteSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, underSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, tomekSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, centroidSampler, rfeLogReg, LogisticRegression(), \"test\")\n",
    "\n",
    "\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, overSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, smoteSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, underSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, tomekSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n",
    "TransformBalanceSelectTrainPredict(X_train, y_train, X_test, y_test, scalerFunc, centroidSampler, rfeSVC, SVC(kernel='linear'), \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Abordagem com bagging através de random forests para superar problema de dataset desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.09      0.11        44\n",
      "           1       0.81      0.87      0.84       196\n",
      "\n",
      "    accuracy                           0.73       240\n",
      "   macro avg       0.47      0.48      0.47       240\n",
      "weighted avg       0.69      0.72      0.70       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "target = AbsenteeismAtWork['Absent']\n",
    "data = AbsenteeismAtWork.drop('Absent', 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform( data )\n",
    "\n",
    "kbest_selector = createKBestSelector(data, target, 10)\n",
    "selected = kbest_selector.transform(data)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_selected = kbest_selector.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(selected, target)\n",
    " \n",
    "pred = clf.predict(X_test_selected)\n",
    " \n",
    "print( accuracy_score(y_test, pred) )\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-Sensitive Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6083333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.27      0.20        44\n",
      "           1       0.81      0.68      0.74       196\n",
      "\n",
      "    accuracy                           0.61       240\n",
      "   macro avg       0.48      0.48      0.47       240\n",
      "weighted avg       0.69      0.61      0.64       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svc = SVC(kernel='linear', \n",
    "            class_weight='balanced', \n",
    "            probability=True)\n",
    "\n",
    "svc.fit(selected, target)\n",
    "\n",
    "predSvc = svc.predict(X_test_selected)\n",
    " \n",
    "print( accuracy_score(y_test, predSvc) )\n",
    "print(classification_report(y_test, predSvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.14      0.16        44\n",
      "           1       0.82      0.87      0.84       196\n",
      "\n",
      "    accuracy                           0.74       240\n",
      "   macro avg       0.51      0.50      0.50       240\n",
      "weighted avg       0.70      0.74      0.72       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "target = AbsenteeismAtWork['Absent']\n",
    "data = AbsenteeismAtWork.drop('Absent', 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform( data )\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "\n",
    "\n",
    "classifier.fit(data, target)\n",
    "\n",
    "predAda = classifier.predict(X_test_scaled)\n",
    " \n",
    "print( accuracy_score(y_test, predAda) )\n",
    "print(classification_report(y_test, predAda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
